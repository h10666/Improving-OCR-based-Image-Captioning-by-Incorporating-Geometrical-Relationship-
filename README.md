# Improving OCR-based Image Captioning by Incorporating Geometrical Relationship 

1.1数据集
在[TextCaps数据集](https://textvqa.org/textcaps/)上评估提出的MMA-SR算法性能。该数据集共包含28408幅图像，每幅图像标注有5个描述句子。测试集中的每幅图像除了5句描述外，还有一个额外标注的句子，用于评估人工描述的表现。公平起见，采用与基准方法相同的数据集分割（21953幅图像用于训练，3166幅用于验证，3289幅用于测试）。所有对比方法均使用标准的图像描述评价指标（CIDEr-D、METEOR、BLEU、ROUGE-L和SPICE）及官方发布的相关代码来评价。

1.2代码介绍
1.	数据集为TextCaps，链接为 https://textvqa.org/textcaps/；
2.	ur_run_showattcat_google+base.sh为算法的训练脚本；
3.	run_eval_test.sh为算法的测试脚本。

1.3论文介绍
MMA-SR算法定义了简单的场景文字空间关系，并人为制定了使用其修正预测词概率的规则，因而无法充分利用场景文字间的关系，且限制了模型自主学习生成场景文字的能力。为解决该问题，本文提出从几何关系的角度进一步增强场景文字之间的关联。其中，在构建几何关系时，综合地考虑场景文字之间的高度、宽度、距离、交并比(IoU)和方向等多个元素;在生成描述时，通过设计一种关系感知指针网络，实现模型在几何关系指导下对场景文字的自主抉择。两者结合既能增强图像中场景文字关联，改善生成结果中场景文字不完整或顺序紊乱等问题;又能避免人为制定规则时可能出现的主观性和片面性等问题。
